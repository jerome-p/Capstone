{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHj9GoioUkZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install pytorch_ssim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-7moFAbUo81",
        "colab_type": "code",
        "outputId": "01562bed-942e-4c29-8984-a0de2f2fbd79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqqcFlVFbM1O",
        "colab_type": "text"
      },
      "source": [
        "PIXEL-SHUFFLE ERROR\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "RuntimeError                              Traceback (most recent call last)\n",
        "<ipython-input-13-a510ddcf6ce0> in <module>()\n",
        "     69         if torch.cuda.is_available():\n",
        "     70             z = z.cuda()\n",
        "---> 71         fake_img = netG(z)\n",
        "     72 \n",
        "     73         netD.zero_grad()\n",
        "\n",
        "7 frames\n",
        "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/pixelshuffle.py in forward(self, input)\n",
        "     44     @weak_script_method\n",
        "     45     def forward(self, input):\n",
        "---> 46         return F.pixel_shuffle(input, self.upscale_factor)\n",
        "     47 \n",
        "     48     def extra_repr(self):\n",
        "\n",
        "RuntimeError: c % upscale_factor_squared == 0 ASSERT FAILED at /pytorch/aten/src/ATen/native/PixelShuffle.cpp:24, please report a bug to PyTorch. pixel_shuffle expects input channel to be divisible by square of upscale_factor, but got input with sizes [64, 256, 29, 29], upscale_factor=3, and self.size(1)=256 is not divisible by 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN0OWHnpbMqU",
        "colab_type": "text"
      },
      "source": [
        "Examples of Pixel Shuffle being used : \n",
        "https://www.programcreek.com/python/example/107679/torch.nn.PixelShuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXBlH7tCvNu4",
        "colab_type": "text"
      },
      "source": [
        "**Network modified to work for any upscale factor:**\n",
        "\n",
        " Instead of using multiple blocks of pixelshuffle(sacel_factor=2). I've used only one block with pixelshuffle(scale_factor=x), where x is whatever scale factor is required.\n",
        "This does not work for fractional sacle values. \n",
        "\n",
        "Also edited the final conv layer to have 64 inputs and 3 outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BHLFbYfVKBu",
        "colab_type": "text"
      },
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peKltlmaVIeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "class pixel_shuffle(nn.Module):\n",
        "    def __init__(self, scale_factor):\n",
        "        super(pixel_shuffle, self).__init__()\n",
        "        self.scale_factor = scale_factor\n",
        "\n",
        "    def forward(self, input):\n",
        "        scale_factor = self.scale_factor\n",
        "        _, in_channels, in_height, in_width = input.shape\n",
        "\n",
        "        in_channels = int(in_channels)\n",
        "        in_height = int(in_height)\n",
        "        in_width = int(in_width)\n",
        "\n",
        "        out_channels = in_channels // (scale_factor * scale_factor)\n",
        "        # out_channels = in_channels / int(scale_factor * scale_factor)\n",
        "        # out_channels = 64\n",
        "        out_height = in_height * scale_factor\n",
        "        out_width = in_width * scale_factor\n",
        "\n",
        "        if scale_factor >= 1:\n",
        "            input_view = input.view([-1, out_channels, int(scale_factor), int(scale_factor), in_height, in_width])\n",
        "            shuffle_out = input_view.permute(0, 1, 4, 2, 5, 3)\n",
        "\n",
        "        return shuffle_out.contiguous().view([-1, out_channels, out_height, out_width])\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, scale_factor):\n",
        "\n",
        "        super(Generator, self).__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=9, padding=4),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        self.block2 = ResidualBlock(64)\n",
        "        self.block3 = ResidualBlock(64)\n",
        "        self.block4 = ResidualBlock(64)\n",
        "        self.block5 = ResidualBlock(64)\n",
        "        self.block6 = ResidualBlock(64)\n",
        "        self.block7 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1, groups=1),\n",
        "            nn.BatchNorm2d(64)\n",
        "            )       \n",
        "        block8 = [UpsampleBLock(64, scale_factor)]\n",
        "        block8.append(nn.Conv2d( 64 , 3, kernel_size=9, padding=4, groups=1))\n",
        "\n",
        "        self.block8 = nn.Sequential(*block8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        block1 = self.block1(x)\n",
        "        block2 = self.block2(block1)\n",
        "        block3 = self.block3(block2)\n",
        "        block4 = self.block4(block3)\n",
        "        block5 = self.block5(block4)\n",
        "        block6 = self.block6(block5)\n",
        "        block7 = self.block7(block6)\n",
        "        block8 = self.block8(block1 + block7)\n",
        "\n",
        "        return (F.tanh(block8) + 1) / 2\n",
        "\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(512, 1024, kernel_size=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(1024, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        return F.sigmoid(self.net(x).view(batch_size))\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.prelu = nn.PReLU()\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.conv1(x)\n",
        "        residual = self.bn1(residual)\n",
        "        residual = self.prelu(residual)\n",
        "        residual = self.conv2(residual)\n",
        "        residual = self.bn2(residual)\n",
        "\n",
        "        return x + residual\n",
        "\n",
        "\n",
        "class UpsampleBLock(nn.Module):\n",
        "    def __init__(self, in_channels, up_scale):\n",
        "        super(UpsampleBLock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, int(in_channels*up_scale ** 2), kernel_size=3, padding=1, groups=1)\n",
        "        # self.pixel_shuffle = nn.PixelShuffle(up_scale)  \n",
        "        self.pixel_shuffle = pixel_shuffle(up_scale)\n",
        "        self.prelu = nn.PReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.pixel_shuffle(x)\n",
        "        x = self.prelu(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Urq-o3d7VMOM",
        "colab_type": "text"
      },
      "source": [
        "utils\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjfJRsjWVIbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from os.path import join\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision.transforms import Compose, RandomCrop, ToTensor, ToPILImage, CenterCrop, Resize\n",
        "\n",
        "\n",
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n",
        "\n",
        "\n",
        "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
        "    return crop_size - (crop_size % int(upscale_factor))\n",
        "\n",
        "\n",
        "def train_hr_transform(crop_size):\n",
        "    return Compose([\n",
        "        RandomCrop(crop_size),\n",
        "        ToTensor(),\n",
        "    ])\n",
        "\n",
        "\n",
        "def train_lr_transform(crop_size, upscale_factor):\n",
        "    return Compose([\n",
        "        ToPILImage(),\n",
        "        Resize(crop_size // int(upscale_factor), interpolation=Image.BICUBIC),\n",
        "        ToTensor()\n",
        "    ])\n",
        "\n",
        "\n",
        "def display_transform():\n",
        "    return Compose([\n",
        "        ToPILImage(),\n",
        "        Resize(400),\n",
        "        CenterCrop(400),\n",
        "        ToTensor()\n",
        "    ])\n",
        "\n",
        "\n",
        "class TrainDatasetFromFolder(Dataset):\n",
        "    def __init__(self, dataset_dir, crop_size, upscale_factor):\n",
        "        super(TrainDatasetFromFolder, self).__init__()\n",
        "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
        "        crop_size = calculate_valid_crop_size(crop_size, upscale_factor)\n",
        "        self.hr_transform = train_hr_transform(crop_size)\n",
        "        self.lr_transform = train_lr_transform(crop_size, upscale_factor)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        hr_image = self.hr_transform(Image.open(self.image_filenames[index]))\n",
        "        lr_image = self.lr_transform(hr_image)\n",
        "        return lr_image, hr_image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "\n",
        "class ValDatasetFromFolder(Dataset):\n",
        "    def __init__(self, dataset_dir, upscale_factor):\n",
        "        super(ValDatasetFromFolder, self).__init__()\n",
        "        self.upscale_factor = upscale_factor\n",
        "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        hr_image = Image.open(self.image_filenames[index])\n",
        "        w, h = hr_image.size\n",
        "        crop_size = calculate_valid_crop_size(min(w, h), self.upscale_factor)\n",
        "        lr_scale = Resize(crop_size // self.upscale_factor, interpolation=Image.BICUBIC)\n",
        "        hr_scale = Resize(crop_size, interpolation=Image.BICUBIC)\n",
        "        hr_image = CenterCrop(crop_size)(hr_image)\n",
        "        lr_image = lr_scale(hr_image)\n",
        "        hr_restore_img = hr_scale(lr_image)\n",
        "        return ToTensor()(lr_image), ToTensor()(hr_restore_img), ToTensor()(hr_image)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "\n",
        "class TestDatasetFromFolder(Dataset):\n",
        "    def __init__(self, dataset_dir, upscale_factor):\n",
        "        super(TestDatasetFromFolder, self).__init__()\n",
        "        # self.lr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/data/'\n",
        "        self.lr_path = dataset_dir + '/set5' + '/data'\n",
        "        # self.hr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/target/'\n",
        "        self.hr_path = dataset_dir + '/set5' + '/target'\n",
        "        self.upscale_factor = upscale_factor\n",
        "        self.lr_filenames = [join(self.lr_path, x) for x in listdir(self.lr_path) if is_image_file(x)]\n",
        "        self.hr_filenames = [join(self.hr_path, x) for x in listdir(self.hr_path) if is_image_file(x)]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = self.lr_filenames[index].split('/')[-1]\n",
        "        lr_image = Image.open(self.lr_filenames[index])\n",
        "        w, h = lr_image.size\n",
        "        hr_image = Image.open(self.hr_filenames[index])\n",
        "        hr_scale = Resize((self.upscale_factor * h, self.upscale_factor * w), interpolation=Image.BICUBIC)\n",
        "        hr_restore_img = hr_scale(lr_image)\n",
        "        return image_name, ToTensor()(lr_image), ToTensor()(hr_restore_img), ToTensor()(hr_image)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lr_filenames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXALscf7Vf0I",
        "colab_type": "text"
      },
      "source": [
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF4bcQ2KVIZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg19\n",
        "\n",
        "\n",
        "class GeneratorLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GeneratorLoss, self).__init__()\n",
        "        vgg = vgg19(pretrained=True)\n",
        "        loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
        "        for param in loss_network.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.loss_network = loss_network\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        self.tv_loss = TVLoss()\n",
        "\n",
        "    def forward(self, out_labels, out_images, target_images):\n",
        "        # Adversarial Loss\n",
        "        adversarial_loss = torch.mean(1 - out_labels)\n",
        "        # Perception Loss\n",
        "        perception_loss = self.mse_loss(self.loss_network(out_images), self.loss_network(target_images))\n",
        "        # Image Loss\n",
        "        image_loss = self.mse_loss(out_images, target_images)\n",
        "        # TV Loss\n",
        "        tv_loss = self.tv_loss(out_images)\n",
        "        return image_loss + 0.001 * adversarial_loss + 0.006 * perception_loss + 2e-8 * tv_loss\n",
        "\n",
        "\n",
        "class TVLoss(nn.Module):\n",
        "    def __init__(self, tv_loss_weight=1):\n",
        "        super(TVLoss, self).__init__()\n",
        "        self.tv_loss_weight = tv_loss_weight\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size()[0]\n",
        "        h_x = x.size()[2]\n",
        "        w_x = x.size()[3]\n",
        "        count_h = self.tensor_size(x[:, :, 1:, :])\n",
        "        count_w = self.tensor_size(x[:, :, :, 1:])\n",
        "        h_tv = torch.pow((x[:, :, 1:, :] - x[:, :, :h_x - 1, :]), 2).sum()\n",
        "        w_tv = torch.pow((x[:, :, :, 1:] - x[:, :, :, :w_x - 1]), 2).sum()\n",
        "        return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
        "\n",
        "    @staticmethod\n",
        "    def tensor_size(t):\n",
        "        return t.size()[1] * t.size()[2] * t.size()[3]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    g_loss = GeneratorLoss()\n",
        "    print(g_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjYG-52eVmFv",
        "colab_type": "text"
      },
      "source": [
        "train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPVp1hvUVIWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from math import log10\n",
        "\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.utils as utils\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "CROP_SIZE = 88 \n",
        "UPSCALE_FACTOR = 4 \n",
        "NUM_EPOCHS = 1000 \n",
        "\n",
        "train_set = TrainDatasetFromFolder('/content/drive/My Drive/vooc2012/train', crop_size=CROP_SIZE, upscale_factor=UPSCALE_FACTOR)\n",
        "val_set = ValDatasetFromFolder('/content/drive/My Drive/vooc2012/val', upscale_factor=UPSCALE_FACTOR)\n",
        "train_loader = DataLoader(dataset=train_set, num_workers=4, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_set, num_workers=4, batch_size=1, shuffle=False)\n",
        "\n",
        "netG = Generator(UPSCALE_FACTOR)\n",
        "print('# generator parameters:', sum(param.numel() for param in netG.parameters()))\n",
        "netD = Discriminator()\n",
        "print('# discriminator parameters:', sum(param.numel() for param in netD.parameters()))\n",
        "\n",
        "generator_criterion = GeneratorLoss()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    netG.cuda()\n",
        "    netD.cuda()\n",
        "    generator_criterion.cuda()\n",
        "\n",
        "optimizerG = optim.Adam(netG.parameters())\n",
        "optimizerD = optim.Adam(netD.parameters())\n",
        "\n",
        "results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': [], 'ssim': []}\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    train_bar = tqdm(train_loader)\n",
        "    running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n",
        "\n",
        "    netG.train()\n",
        "    netD.train()\n",
        "    for data, target in train_bar:\n",
        "        g_update_first = True\n",
        "        batch_size = data.size(0)\n",
        "        running_results['batch_sizes'] += batch_size\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize D(x)-1-D(G(z))\n",
        "        ###########################\n",
        "        real_img = Variable(target)\n",
        "        if torch.cuda.is_available():\n",
        "            real_img = real_img.cuda()\n",
        "        z = Variable(data)\n",
        "        if torch.cuda.is_available():\n",
        "            z = z.cuda()\n",
        "        fake_img = netG(z)\n",
        "        \n",
        "        netD.zero_grad()\n",
        "        real_out = netD(real_img).mean()\n",
        "        fake_out = netD(fake_img).mean()\n",
        "        d_loss = 1 - real_out + fake_out\n",
        "        d_loss.backward(retain_graph=True)\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: minimize 1-D(G(z)) + Perception Loss + Image Loss + TV Loss\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
        "        g_loss.backward()\n",
        "        optimizerG.step()\n",
        "        fake_img = netG(z)\n",
        "        fake_out = netD(fake_img).mean()\n",
        "\n",
        "        g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
        "        running_results['g_loss'] += g_loss.data * batch_size\n",
        "        d_loss = 1 - real_out + fake_out\n",
        "        running_results['d_loss'] += d_loss.data * batch_size\n",
        "        running_results['d_score'] += real_out.data * batch_size\n",
        "        running_results['g_score'] += fake_out.data * batch_size\n",
        "\n",
        "        train_bar.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f batch_size: %.4f' % (\n",
        "            epoch, NUM_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],\n",
        "            running_results['g_loss'] / running_results['batch_sizes'],\n",
        "            running_results['d_score'] / running_results['batch_sizes'],\n",
        "            running_results['g_score'] / running_results['batch_sizes'],\n",
        "            running_results['batch_sizes']))\n",
        "    \n",
        "    print('-----------------')\n",
        "    print('LR image size:{}\\n'.format(list(z.size())))\n",
        "    print('SR image size:{}\\n'.format(list(fake_img.size())))\n",
        "    print('-----------------')\n",
        "\n",
        "    netG.eval()\n",
        "    out_path = 'training_results/SRF_' + str(UPSCALE_FACTOR) + '/'\n",
        "    if not os.path.exists(out_path):\n",
        "        os.makedirs(out_path)\n",
        "    val_bar = tqdm(val_loader)\n",
        "    valing_results = {'mse': 0, 'ssims': 0, 'psnr': 0, 'ssim': 0, 'batch_sizes': 0}\n",
        "    val_images = []\n",
        "    for val_lr, val_hr_restore, val_hr in val_bar:\n",
        "        batch_size = val_lr.size(0)\n",
        "        valing_results['batch_sizes'] += batch_size\n",
        "        lr = Variable(val_lr, volatile=True)\n",
        "        hr = Variable(val_hr, volatile=True)\n",
        "        if torch.cuda.is_available():\n",
        "            lr = lr.cuda()\n",
        "            hr = hr.cuda()\n",
        "        sr = netG(lr)\n",
        "\n",
        "        batch_mse = ((sr - hr) ** 2).data.mean()\n",
        "        valing_results['mse'] += batch_mse * batch_size\n",
        "        valing_results['psnr'] = 10 * log10(1 / (valing_results['mse'] / valing_results['batch_sizes']))\n",
        "        val_bar.set_description(\n",
        "            desc='[converting LR images to SR images] PSNR: %.4f dB ' % (\n",
        "                valing_results['psnr']))\n",
        "\n",
        "        val_images.extend(\n",
        "            [display_transform()(val_hr_restore.squeeze(0)), display_transform()(hr.data.cpu().squeeze(0)),\n",
        "             display_transform()(sr.data.cpu().squeeze(0))])\n",
        "    val_images = torch.stack(val_images)\n",
        "    val_images = torch.chunk(val_images, val_images.size(0) // 15)\n",
        "    val_save_bar = tqdm(val_images, desc='[saving training results]')\n",
        "    index = 1\n",
        "    for image in val_save_bar:\n",
        "        image = utils.make_grid(image, nrow=3, padding=5)\n",
        "        utils.save_image(image, out_path + 'epoch_%d_index_%d.png' % (epoch, index), padding=5)\n",
        "        index += 1\n",
        "\n",
        "    torch.save(netG.state_dict(), 'netG_epoch_%d_%d.pth' % (UPSCALE_FACTOR, epoch))\n",
        "    torch.save(netD.state_dict(), 'netD_epoch_%d_%d.pth' % (UPSCALE_FACTOR, epoch))\n",
        "    # save loss\\scores\\psnr\\ssim\n",
        "    results['d_loss'].append(running_results['d_loss'] / running_results['batch_sizes'])\n",
        "    results['g_loss'].append(running_results['g_loss'] / running_results['batch_sizes'])\n",
        "    results['d_score'].append(running_results['d_score'] / running_results['batch_sizes'])\n",
        "    results['g_score'].append(running_results['g_score'] / running_results['batch_sizes'])\n",
        "    results['psnr'].append(valing_results['psnr'])\n",
        "\n",
        "    if epoch % 10 == 0 and epoch != 0:  \n",
        "        # out_path = 'statistics/'\n",
        "        data_frame = pd.DataFrame( data={'Loss_D': results['d_loss'],\n",
        "                                         'Loss_G': results['g_loss'],\n",
        "                                         'Score_D': results['d_score'],\n",
        "                                         'Score_G': results['g_score'],\n",
        "                                         'PSNR': results['psnr'],\n",
        "                                         },\n",
        "                                  index=list(range(1, epoch + 1))\n",
        "                                  )\n",
        "        data_frame.to_csv( 'srf_' + str(UPSCALE_FACTOR) + '_train_results.csv', index_label='Epoch')\n",
        "\n",
        "        # out_path\n",
        "        # 'SSIM': results['ssim']   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw-NlJLoJjMl",
        "colab_type": "text"
      },
      "source": [
        "# generator parameters: 669594\n",
        "# discriminator parameters: 5215425\n",
        "\n",
        "  0%|          | 0/17 [00:00<?, ?it/s]\n",
        "---------------------------------------------------------------------------\n",
        "TypeError                                 Traceback (most recent call last)\n",
        "<ipython-input-18-8a6e2b51ad98> in <module>()\n",
        "     69         if torch.cuda.is_available():\n",
        "     70             z = z.cuda()\n",
        "---> 71         fake_img = netG(z)\n",
        "     72 \n",
        "     73         netD.zero_grad()\n",
        "\n",
        "7 frames\n",
        "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/pixelshuffle.py in forward(self, input)\n",
        "     44     @weak_script_method\n",
        "     45     def forward(self, input):\n",
        "---> 46         return F.pixel_shuffle(input, self.upscale_factor)\n",
        "     47 \n",
        "     48     def extra_repr(self):\n",
        "\n",
        "TypeError: pixel_shuffle(): argument 'upscale_factor' (position 2) must be int, not float"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFE--EjSJkki",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_oETDBXWDRh",
        "colab_type": "text"
      },
      "source": [
        "single image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plSgn-wwVIRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import argparse\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "\n",
        "UPSCALE_FACTOR = 4 \n",
        "TEST_MODE = True #True if opt.test_mode == 'GPU' else False\n",
        "IMAGE_NAME = '0016x4.png'\n",
        "MODEL_NAME = 'netG_epoch_4_931.pth'  \n",
        "\n",
        "model = Generator(UPSCALE_FACTOR).eval()\n",
        "if TEST_MODE:\n",
        "    model.cuda()\n",
        "    model.load_state_dict(torch.load( MODEL_NAME)) \n",
        "else:\n",
        "    model.load_state_dict(torch.load( MODEL_NAME, map_location=lambda storage, loc: storage)) \n",
        "\n",
        "image = Image.open(IMAGE_NAME)\n",
        "image = Variable(ToTensor()(image), volatile=True).unsqueeze(0)\n",
        "if TEST_MODE:\n",
        "    image = image.cuda()\n",
        "\n",
        "start = time.clock()\n",
        "out = model(image)\n",
        "elapsed = (time.clock() - start)\n",
        "print('cost' + str(elapsed) + 's')\n",
        "out_img = ToPILImage()(out[0].data.cpu())\n",
        "out_img.save('out_srf_' + str(UPSCALE_FACTOR) + '_' + IMAGE_NAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi6_79EID4ki",
        "colab_type": "text"
      },
      "source": [
        "Single Image with PSNR calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YGqJ53bVIGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "from math import log10\n",
        "\n",
        "\n",
        "UPSCALE_FACTOR = 4\n",
        "TEST_MODE = True #True if opt.test_mode == 'GPU' else False\n",
        "IMAGE_NAME = '22-4x.jpg'\n",
        "MODEL_NAME = 'netG_epoch_4_931.pth' \n",
        "hr_image = '11-4x.jpg'\n",
        "\n",
        "model = Generator(UPSCALE_FACTOR).eval()\n",
        "if TEST_MODE:\n",
        "    model.cuda()\n",
        "    model.load_state_dict(torch.load( MODEL_NAME))\n",
        "else:\n",
        "    model.load_state_dict(torch.load( MODEL_NAME, map_location=lambda storage, loc: storage)) \n",
        "\n",
        "image = Image.open(IMAGE_NAME)\n",
        "hr = Image.open(hr_image)\n",
        "\n",
        "image = Variable(ToTensor()(image), volatile=True).unsqueeze(0)\n",
        "hr = Variable(ToTensor()(hr), volatile=True).unsqueeze(0)\n",
        "\n",
        "if TEST_MODE:\n",
        "    image = image.cuda()\n",
        "    hr = hr.cuda()\n",
        "\n",
        "start = time.clock()\n",
        "out = model(image)\n",
        "elapsed = (time.clock() - start)\n",
        "print('cost for {}:{}s\\n'.format(IMAGE_NAME,str(elapsed)))\n",
        "\n",
        "# print('cost' + str(elapsed) + 's')\n",
        "mse = ((hr - out) ** 2).data.mean()\n",
        "psnr = 10 * log10(1 / mse)\n",
        "print('PSNR value for {}:{}\\n'.format(IMAGE_NAME,psnr))\n",
        "out_img = ToPILImage()(out[0].data.cpu())\n",
        "out_img.save('out_srf_' + str(UPSCALE_FACTOR) + '_' + IMAGE_NAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRi54-WoEmS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.get_device_name(torch.cuda.current_device())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrDWqSUeYv15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hr_image = 'baby_rlt.png'\n",
        "# hr = Image.open(hr_image)\n",
        "# hr = Variable(ToTensor()(hr), volatile=True)\n",
        "\n",
        "# mse = ((hr - out_t) ** 2).data.mean()\n",
        "# psnr = 10 * log10(1 / mse)\n",
        "# print(psnr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIUmarjdbDAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# data = pd.read_csv('srf_5_train_results111.csv')\n",
        "# data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppznOkZM8SWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# epochs = data.iloc[:,0]\n",
        "# loss_d = data['Loss_D']\n",
        "# # loss_d.head()\n",
        "\n",
        "# loss_g = data['Loss_G']\n",
        "# # loss_g.head()\n",
        "# epochs.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdbY-mwa8y_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.plot(epochs, loss_g)\n",
        "# plt.ylabel('Generator Loss')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.savefig('Generator_loss_100epx5')\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itxhueoy9lFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.plot(epochs, loss_d)\n",
        "# plt.ylabel('Discriminator Loss')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.savefig('Discriminator_loss_100epx5')\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzyBa-pS-w5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}