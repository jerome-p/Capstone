{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHj9GoioUkZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# !pip install pytorch_ssim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-7moFAbUo81",
        "colab_type": "code",
        "outputId": "c0e5b104-6ece-475b-c85f-bd78300564b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqqcFlVFbM1O",
        "colab_type": "text"
      },
      "source": [
        "PIXEL-SHUFFLE ERROR\n",
        "\n",
        "---------------------------------------------------------------------------\n",
        "RuntimeError                              Traceback (most recent call last)\n",
        "<ipython-input-13-a510ddcf6ce0> in <module>()\n",
        "     69         if torch.cuda.is_available():\n",
        "     70             z = z.cuda()\n",
        "---> 71         fake_img = netG(z)\n",
        "     72 \n",
        "     73         netD.zero_grad()\n",
        "\n",
        "7 frames\n",
        "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/pixelshuffle.py in forward(self, input)\n",
        "     44     @weak_script_method\n",
        "     45     def forward(self, input):\n",
        "---> 46         return F.pixel_shuffle(input, self.upscale_factor)\n",
        "     47 \n",
        "     48     def extra_repr(self):\n",
        "\n",
        "RuntimeError: c % upscale_factor_squared == 0 ASSERT FAILED at /pytorch/aten/src/ATen/native/PixelShuffle.cpp:24, please report a bug to PyTorch. pixel_shuffle expects input channel to be divisible by square of upscale_factor, but got input with sizes [64, 256, 29, 29], upscale_factor=3, and self.size(1)=256 is not divisible by 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN0OWHnpbMqU",
        "colab_type": "text"
      },
      "source": [
        "Examples of Pixel Shuffle being used : \n",
        "https://www.programcreek.com/python/example/107679/torch.nn.PixelShuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXBlH7tCvNu4",
        "colab_type": "text"
      },
      "source": [
        "**Network modified to work for any upscale factor:**\n",
        "\n",
        " Instead of using multiple blocks of pixelshuffle(sacel_factor=2). I've used only one block with pixelshuffle(scale_factor=x), where x is whatever scale factor is required.\n",
        "This does not work for fractional sacle values. \n",
        "\n",
        "Also edited the final conv layer to have 64 inputs and 3 outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BHLFbYfVKBu",
        "colab_type": "text"
      },
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eFe9Aa_9yt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, scale_factor):\n",
        "        upsample_block_num = int(math.log(scale_factor, 2))\n",
        "\n",
        "        super(Generator, self).__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=9, padding=4),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        self.block2 = ResidualBlock(64)\n",
        "        self.block3 = ResidualBlock(64)\n",
        "        self.block4 = ResidualBlock(64)\n",
        "        self.block5 = ResidualBlock(64)\n",
        "        self.block6 = ResidualBlock(64)\n",
        "        self.block7 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64)\n",
        "        )\n",
        "        block8 = [UpsampleBLock(64, 2) for _ in range(upsample_block_num)]\n",
        "        block8.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))\n",
        "        self.block8 = nn.Sequential(*block8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        block1 = self.block1(x)\n",
        "        block2 = self.block2(block1)\n",
        "        block3 = self.block3(block2)\n",
        "        block4 = self.block4(block3)\n",
        "        block5 = self.block5(block4)\n",
        "        block6 = self.block6(block5)\n",
        "        block7 = self.block7(block6)\n",
        "        block8 = self.block8(block1 + block7)\n",
        "\n",
        "        return (torch.tanh(block8) + 1) / 2\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.prelu = nn.PReLU()\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.conv1(x)\n",
        "        residual = self.bn1(residual)\n",
        "        residual = self.prelu(residual)\n",
        "        residual = self.conv2(residual)\n",
        "        residual = self.bn2(residual)\n",
        "\n",
        "        return x + residual\n",
        "\n",
        "\n",
        "class UpsampleBLock(nn.Module):\n",
        "    def __init__(self, in_channels, up_scale):\n",
        "        super(UpsampleBLock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2, kernel_size=3, padding=1)\n",
        "        self.pixel_shuffle = nn.PixelShuffle(up_scale)\n",
        "        self.prelu = nn.PReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.pixel_shuffle(x)\n",
        "        x = self.prelu(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a_Z7_D0909p",
        "colab_type": "text"
      },
      "source": [
        "Modified model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peKltlmaVIeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "class pixel_shuffle(nn.Module):\n",
        "    def __init__(self, scale_factor):\n",
        "        super(pixel_shuffle, self).__init__()\n",
        "        self.scale_factor = scale_factor\n",
        "\n",
        "    def forward(self, input):\n",
        "        scale_factor = self.scale_factor\n",
        "        _, in_channels, in_height, in_width = input.shape\n",
        "\n",
        "        in_channels = int(in_channels)\n",
        "        in_height = int(in_height)\n",
        "        in_width = int(in_width)\n",
        "\n",
        "        out_channels = in_channels // (scale_factor * scale_factor)\n",
        "        # out_channels = in_channels / int(scale_factor * scale_factor)\n",
        "        # out_channels = 64\n",
        "        out_height = in_height * scale_factor\n",
        "        out_width = in_width * scale_factor\n",
        "\n",
        "        if scale_factor >= 1:\n",
        "            input_view = input.view([-1, out_channels, int(scale_factor), int(scale_factor), in_height, in_width])\n",
        "            shuffle_out = input_view.permute(0, 1, 4, 2, 5, 3)\n",
        "\n",
        "        return shuffle_out.contiguous().view([-1, out_channels, out_height, out_width])\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, scale_factor):\n",
        "\n",
        "        super(Generator, self).__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=9, padding=4),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        self.block2 = ResidualBlock(64)\n",
        "        self.block3 = ResidualBlock(64)\n",
        "        self.block4 = ResidualBlock(64)\n",
        "        self.block5 = ResidualBlock(64)\n",
        "        self.block6 = ResidualBlock(64)\n",
        "        self.block7 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1, groups=1),\n",
        "            nn.BatchNorm2d(64)\n",
        "            )       \n",
        "        block8 = [UpsampleBLock(64, scale_factor)]\n",
        "        block8.append(nn.Conv2d( 64 , 3, kernel_size=9, padding=4, groups=1))\n",
        "\n",
        "        self.block8 = nn.Sequential(*block8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        block1 = self.block1(x)\n",
        "        block2 = self.block2(block1)\n",
        "        block3 = self.block3(block2)\n",
        "        block4 = self.block4(block3)\n",
        "        block5 = self.block5(block4)\n",
        "        block6 = self.block6(block5)\n",
        "        block7 = self.block7(block6)\n",
        "        block8 = self.block8(block1 + block7)\n",
        "\n",
        "        return (F.tanh(block8) + 1) / 2\n",
        "\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(512, 1024, kernel_size=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(1024, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        return F.sigmoid(self.net(x).view(batch_size))\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.prelu = nn.PReLU()\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.conv1(x)\n",
        "        residual = self.bn1(residual)\n",
        "        residual = self.prelu(residual)\n",
        "        residual = self.conv2(residual)\n",
        "        residual = self.bn2(residual)\n",
        "\n",
        "        return x + residual\n",
        "\n",
        "\n",
        "class UpsampleBLock(nn.Module):\n",
        "    def __init__(self, in_channels, up_scale):\n",
        "        super(UpsampleBLock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, int(in_channels*up_scale ** 2), kernel_size=3, padding=1, groups=1)\n",
        "        # self.pixel_shuffle = nn.PixelShuffle(up_scale)  \n",
        "        self.pixel_shuffle = pixel_shuffle(up_scale)\n",
        "        self.prelu = nn.PReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.pixel_shuffle(x)\n",
        "        x = self.prelu(x)\n",
        "        return x\n",
        "\n",
        "# from torchsummary import summary\n",
        "# # print(Generator(scale_factor=4))\n",
        "# summary(Generator(scale_factor=4), input_size=(3, 22, 22))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Urq-o3d7VMOM",
        "colab_type": "text"
      },
      "source": [
        "utils\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdZQ4kgNHnto",
        "colab_type": "code",
        "outputId": "5f17cee7-96e8-4cd9-a954-b5234ea6f934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! pip install torchsummary"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjfJRsjWVIbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from os.path import join\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision.transforms import Compose, RandomCrop, ToTensor, ToPILImage, CenterCrop, Resize\n",
        "\n",
        "\n",
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n",
        "\n",
        "\n",
        "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
        "    return crop_size - (crop_size % int(upscale_factor))\n",
        "\n",
        "\n",
        "def train_hr_transform(crop_size):\n",
        "    return Compose([\n",
        "        RandomCrop(crop_size),\n",
        "        ToTensor(),\n",
        "    ])\n",
        "\n",
        "\n",
        "def train_lr_transform(crop_size, upscale_factor):\n",
        "    return Compose([\n",
        "        ToPILImage(),\n",
        "        Resize(crop_size // int(upscale_factor), interpolation=Image.BICUBIC),\n",
        "        ToTensor()\n",
        "    ])\n",
        "\n",
        "\n",
        "def display_transform():\n",
        "    return Compose([\n",
        "        ToPILImage(),\n",
        "        Resize(400),\n",
        "        CenterCrop(400),\n",
        "        ToTensor()\n",
        "    ])\n",
        "\n",
        "\n",
        "class TrainDatasetFromFolder(Dataset):\n",
        "    def __init__(self, dataset_dir, crop_size, upscale_factor):\n",
        "        super(TrainDatasetFromFolder, self).__init__()\n",
        "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
        "        crop_size = calculate_valid_crop_size(crop_size, upscale_factor)\n",
        "        self.hr_transform = train_hr_transform(crop_size)\n",
        "        self.lr_transform = train_lr_transform(crop_size, upscale_factor)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        hr_image = self.hr_transform(Image.open(self.image_filenames[index]))\n",
        "        lr_image = self.lr_transform(hr_image)\n",
        "        return lr_image, hr_image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "\n",
        "class ValDatasetFromFolder(Dataset):\n",
        "    def __init__(self, dataset_dir, upscale_factor):\n",
        "        super(ValDatasetFromFolder, self).__init__()\n",
        "        self.upscale_factor = upscale_factor\n",
        "        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        hr_image = Image.open(self.image_filenames[index])\n",
        "        w, h = hr_image.size\n",
        "        crop_size = calculate_valid_crop_size(min(w, h), self.upscale_factor)\n",
        "        lr_scale = Resize(crop_size // self.upscale_factor, interpolation=Image.BICUBIC)\n",
        "        hr_scale = Resize(crop_size, interpolation=Image.BICUBIC)\n",
        "        hr_image = CenterCrop(crop_size)(hr_image)\n",
        "        lr_image = lr_scale(hr_image)\n",
        "        hr_restore_img = hr_scale(lr_image)\n",
        "        return ToTensor()(lr_image), ToTensor()(hr_restore_img), ToTensor()(hr_image)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "\n",
        "class TestDatasetFromFolder(Dataset):\n",
        "    def __init__(self, dataset_dir, upscale_factor):\n",
        "        super(TestDatasetFromFolder, self).__init__()\n",
        "        # self.lr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/data/'\n",
        "        self.lr_path = dataset_dir + '/set5' + '/data'\n",
        "        # self.hr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/target/'\n",
        "        self.hr_path = dataset_dir + '/set5' + '/target'\n",
        "        self.upscale_factor = upscale_factor\n",
        "        self.lr_filenames = [join(self.lr_path, x) for x in listdir(self.lr_path) if is_image_file(x)]\n",
        "        self.hr_filenames = [join(self.hr_path, x) for x in listdir(self.hr_path) if is_image_file(x)]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = self.lr_filenames[index].split('/')[-1]\n",
        "        lr_image = Image.open(self.lr_filenames[index])\n",
        "        w, h = lr_image.size\n",
        "        hr_image = Image.open(self.hr_filenames[index])\n",
        "        hr_scale = Resize((self.upscale_factor * h, self.upscale_factor * w), interpolation=Image.BICUBIC)\n",
        "        hr_restore_img = hr_scale(lr_image)\n",
        "        return image_name, ToTensor()(lr_image), ToTensor()(hr_restore_img), ToTensor()(hr_image)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lr_filenames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXALscf7Vf0I",
        "colab_type": "text"
      },
      "source": [
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF4bcQ2KVIZI",
        "colab_type": "code",
        "outputId": "1c370591-4111-47b1-ac2d-737aebb284a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg19\n",
        "\n",
        "\n",
        "class GeneratorLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GeneratorLoss, self).__init__()\n",
        "        vgg = vgg19(pretrained=True)\n",
        "        loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
        "        for param in loss_network.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.loss_network = loss_network\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        self.tv_loss = TVLoss()\n",
        "\n",
        "    def forward(self, out_labels, out_images, target_images):\n",
        "        # Adversarial Loss\n",
        "        adversarial_loss = torch.mean(1 - out_labels)\n",
        "        # Perception Loss\n",
        "        perception_loss = self.mse_loss(self.loss_network(out_images), self.loss_network(target_images))\n",
        "        # Image Loss\n",
        "        image_loss = self.mse_loss(out_images, target_images)\n",
        "        # TV Loss\n",
        "        tv_loss = self.tv_loss(out_images)\n",
        "        return image_loss + 0.001 * adversarial_loss + 0.006 * perception_loss + 2e-8 * tv_loss\n",
        "\n",
        "\n",
        "class TVLoss(nn.Module):\n",
        "    def __init__(self, tv_loss_weight=1):\n",
        "        super(TVLoss, self).__init__()\n",
        "        self.tv_loss_weight = tv_loss_weight\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size()[0]\n",
        "        h_x = x.size()[2]\n",
        "        w_x = x.size()[3]\n",
        "        count_h = self.tensor_size(x[:, :, 1:, :])\n",
        "        count_w = self.tensor_size(x[:, :, :, 1:])\n",
        "        h_tv = torch.pow((x[:, :, 1:, :] - x[:, :, :h_x - 1, :]), 2).sum()\n",
        "        w_tv = torch.pow((x[:, :, :, 1:] - x[:, :, :, :w_x - 1]), 2).sum()\n",
        "        return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
        "\n",
        "    @staticmethod\n",
        "    def tensor_size(t):\n",
        "        return t.size()[1] * t.size()[2] * t.size()[3]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    g_loss = GeneratorLoss()\n",
        "    print(g_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GeneratorLoss(\n",
            "  (loss_network): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (mse_loss): MSELoss()\n",
            "  (tv_loss): TVLoss()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjYG-52eVmFv",
        "colab_type": "text"
      },
      "source": [
        "train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPVp1hvUVIWY",
        "colab_type": "code",
        "outputId": "a1137980-c9e1-4836-e3b9-158835a88d18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "from math import log10\n",
        "\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.utils as utils\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "CROP_SIZE = 88 \n",
        "UPSCALE_FACTOR = 4 \n",
        "NUM_EPOCHS = 1 \n",
        "\n",
        "train_set = TrainDatasetFromFolder('/content/drive/My Drive/vooc2012/train', crop_size=CROP_SIZE, upscale_factor=UPSCALE_FACTOR)\n",
        "val_set = ValDatasetFromFolder('/content/drive/My Drive/vooc2012/val', upscale_factor=UPSCALE_FACTOR)\n",
        "train_loader = DataLoader(dataset=train_set, num_workers=4, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_set, num_workers=4, batch_size=1, shuffle=False)\n",
        "\n",
        "netG = Generator(UPSCALE_FACTOR)\n",
        "print('# generator parameters:', sum(param.numel() for param in netG.parameters()))\n",
        "netD = Discriminator()\n",
        "print('# discriminator parameters:', sum(param.numel() for param in netD.parameters()))\n",
        "\n",
        "generator_criterion = GeneratorLoss()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    netG.cuda()\n",
        "    netD.cuda()\n",
        "    generator_criterion.cuda()\n",
        "\n",
        "from torchsummary import summary\n",
        "# # print(Generator(scale_factor=4))\n",
        "summary(netG, input_size=(3, 22, 22))\n",
        "\n",
        "\n",
        "optimizerG = optim.Adam(netG.parameters())\n",
        "optimizerD = optim.Adam(netD.parameters())\n",
        "\n",
        "results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': [], 'ssim': []}\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    train_bar = tqdm(train_loader)\n",
        "    running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n",
        "\n",
        "    netG.train()\n",
        "    netD.train()\n",
        "    for data, target in train_bar:\n",
        "        g_update_first = True\n",
        "        batch_size = data.size(0)\n",
        "        running_results['batch_sizes'] += batch_size\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize D(x)-1-D(G(z))\n",
        "        ###########################\n",
        "        real_img = Variable(target)\n",
        "        if torch.cuda.is_available():\n",
        "            real_img = real_img.cuda()\n",
        "        z = Variable(data)\n",
        "        if torch.cuda.is_available():\n",
        "            z = z.cuda()\n",
        "        fake_img = netG(z)\n",
        "        # print(\"FAKE\\n\")\n",
        "        # print(len(fake_img))\n",
        "        # plt.imshow(fake_img[0])\n",
        "\n",
        "        netD.zero_grad()\n",
        "        real_out = netD(real_img).mean()\n",
        "        fake_out = netD(fake_img).mean()\n",
        "\n",
        "        # print(f\"Without mean, real_out: {netD(real_img)}\")\n",
        "        # print(f\"With mean, real_out: {real_out}\")\n",
        "        # print(f\"Without mean, fake_out: {netD(fake_img)}\")\n",
        "        # print(f\"With mean, fake_out: {fake_out}\")\n",
        "\n",
        "        d_loss = 1 - real_out + fake_out\n",
        "        d_loss.backward(retain_graph=True)\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: minimize 1-D(G(z)) + Perception Loss + Image Loss + TV Loss\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
        "        g_loss.backward()\n",
        "        optimizerG.step()\n",
        "        fake_img = netG(z)\n",
        "        fake_out = netD(fake_img).mean()\n",
        "\n",
        "        g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
        "        running_results['g_loss'] += g_loss.data * batch_size\n",
        "        d_loss = 1 - real_out + fake_out\n",
        "        running_results['d_loss'] += d_loss.data * batch_size\n",
        "        running_results['d_score'] += real_out.data * batch_size\n",
        "        running_results['g_score'] += fake_out.data * batch_size\n",
        "\n",
        "        train_bar.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f batch_size: %.4f' % (\n",
        "            epoch, NUM_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],\n",
        "            running_results['g_loss'] / running_results['batch_sizes'],\n",
        "            running_results['d_score'] / running_results['batch_sizes'],\n",
        "            running_results['g_score'] / running_results['batch_sizes'],\n",
        "            running_results['batch_sizes']))\n",
        "    \n",
        "    print('-----------------')\n",
        "    print('LR image size:{}\\n'.format(list(z.size())))\n",
        "    print('SR image size:{}\\n'.format(list(fake_img.size())))\n",
        "    print('-----------------')\n",
        "\n",
        "    netG.eval()\n",
        "    out_path = 'training_results/SRF_' + str(UPSCALE_FACTOR) + '/'\n",
        "    if not os.path.exists(out_path):\n",
        "        os.makedirs(out_path)\n",
        "    val_bar = tqdm(val_loader)\n",
        "    valing_results = {'mse': 0, 'ssims': 0, 'psnr': 0, 'ssim': 0, 'batch_sizes': 0}\n",
        "    val_images = []\n",
        "    for val_lr, val_hr_restore, val_hr in val_bar:\n",
        "        batch_size = val_lr.size(0)\n",
        "        valing_results['batch_sizes'] += batch_size\n",
        "        lr = Variable(val_lr, volatile=True)\n",
        "        hr = Variable(val_hr, volatile=True)\n",
        "        if torch.cuda.is_available():\n",
        "            lr = lr.cuda()\n",
        "            hr = hr.cuda()\n",
        "        sr = netG(lr)\n",
        "\n",
        "        batch_mse = ((sr - hr) ** 2).data.mean()\n",
        "        valing_results['mse'] += batch_mse * batch_size\n",
        "        valing_results['psnr'] = 10 * log10(1 / (valing_results['mse'] / valing_results['batch_sizes']))\n",
        "        val_bar.set_description(\n",
        "            desc='[converting LR images to SR images] PSNR: %.4f dB ' % (\n",
        "                valing_results['psnr']))\n",
        "\n",
        "        val_images.extend(\n",
        "            [display_transform()(val_hr_restore.squeeze(0)), display_transform()(hr.data.cpu().squeeze(0)),\n",
        "             display_transform()(sr.data.cpu().squeeze(0))])\n",
        "    val_images = torch.stack(val_images)\n",
        "    val_images = torch.chunk(val_images, val_images.size(0) // 15)\n",
        "    val_save_bar = tqdm(val_images, desc='[saving training results]')\n",
        "    index = 1\n",
        "    for image in val_save_bar:\n",
        "        image = utils.make_grid(image, nrow=3, padding=5)\n",
        "        utils.save_image(image, out_path + 'epoch_%d_index_%d.png' % (epoch, index), padding=5)\n",
        "        index += 1\n",
        "\n",
        "    torch.save(netG.state_dict(), 'netG_epoch_%d_%d.pth' % (UPSCALE_FACTOR, epoch))\n",
        "    torch.save(netD.state_dict(), 'netD_epoch_%d_%d.pth' % (UPSCALE_FACTOR, epoch))\n",
        "    # save loss\\scores\\psnr\\ssim\n",
        "    results['d_loss'].append(running_results['d_loss'] / running_results['batch_sizes'])\n",
        "    results['g_loss'].append(running_results['g_loss'] / running_results['batch_sizes'])\n",
        "    results['d_score'].append(running_results['d_score'] / running_results['batch_sizes'])\n",
        "    results['g_score'].append(running_results['g_score'] / running_results['batch_sizes'])\n",
        "    results['psnr'].append(valing_results['psnr'])\n",
        "\n",
        "    if epoch % 10 == 0 and epoch != 0:  \n",
        "        # out_path = 'statistics/'\n",
        "        data_frame = pd.DataFrame( data={'Loss_D': results['d_loss'],\n",
        "                                         'Loss_G': results['g_loss'],\n",
        "                                         'Score_D': results['d_score'],\n",
        "                                         'Score_G': results['g_score'],\n",
        "                                         'PSNR': results['psnr'],\n",
        "                                         },\n",
        "                                  index=list(range(1, epoch + 1))\n",
        "                                  )\n",
        "        data_frame.to_csv( 'srf_' + str(UPSCALE_FACTOR) + '_train_results.csv', index_label='Epoch')\n",
        "\n",
        "        # out_path\n",
        "        # 'SSIM': results['ssim']   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# generator parameters: 1029642\n",
            "# discriminator parameters: 5215425\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "\r  0%|          | 0/17 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 22, 22]          15,616\n",
            "             PReLU-2           [-1, 64, 22, 22]               1\n",
            "            Conv2d-3           [-1, 64, 22, 22]          36,928\n",
            "       BatchNorm2d-4           [-1, 64, 22, 22]             128\n",
            "             PReLU-5           [-1, 64, 22, 22]               1\n",
            "            Conv2d-6           [-1, 64, 22, 22]          36,928\n",
            "       BatchNorm2d-7           [-1, 64, 22, 22]             128\n",
            "     ResidualBlock-8           [-1, 64, 22, 22]               0\n",
            "            Conv2d-9           [-1, 64, 22, 22]          36,928\n",
            "      BatchNorm2d-10           [-1, 64, 22, 22]             128\n",
            "            PReLU-11           [-1, 64, 22, 22]               1\n",
            "           Conv2d-12           [-1, 64, 22, 22]          36,928\n",
            "      BatchNorm2d-13           [-1, 64, 22, 22]             128\n",
            "    ResidualBlock-14           [-1, 64, 22, 22]               0\n",
            "           Conv2d-15           [-1, 64, 22, 22]          36,928\n",
            "      BatchNorm2d-16           [-1, 64, 22, 22]             128\n",
            "            PReLU-17           [-1, 64, 22, 22]               1\n",
            "           Conv2d-18           [-1, 64, 22, 22]          36,928\n",
            "      BatchNorm2d-19           [-1, 64, 22, 22]             128\n",
            "    ResidualBlock-20           [-1, 64, 22, 22]               0\n",
            "           Conv2d-21           [-1, 64, 22, 22]          36,928\n",
            "      BatchNorm2d-22           [-1, 64, 22, 22]             128\n",
            "            PReLU-23           [-1, 64, 22, 22]               1\n",
            "           Conv2d-24           [-1, 64, 22, 22]          36,928\n",
            "      BatchNorm2d-25           [-1, 64, 22, 22]             128\n",
            "    ResidualBlock-26           [-1, 64, 22, 22]               0\n",
            "           Conv2d-27           [-1, 64, 22, 22]          36,928\n",
            "      BatchNorm2d-28           [-1, 64, 22, 22]             128\n",
            "            PReLU-29           [-1, 64, 22, 22]               1\n",
            "           Conv2d-30           [-1, 64, 22, 22]          36,928\n",
            "      BatchNorm2d-31           [-1, 64, 22, 22]             128\n",
            "    ResidualBlock-32           [-1, 64, 22, 22]               0\n",
            "           Conv2d-33           [-1, 64, 22, 22]          36,928\n",
            "      BatchNorm2d-34           [-1, 64, 22, 22]             128\n",
            "           Conv2d-35         [-1, 1024, 22, 22]         590,848\n",
            "    pixel_shuffle-36           [-1, 64, 88, 88]               0\n",
            "            PReLU-37           [-1, 64, 88, 88]               1\n",
            "    UpsampleBLock-38           [-1, 64, 88, 88]               0\n",
            "           Conv2d-39            [-1, 3, 88, 88]          15,555\n",
            "================================================================\n",
            "Total params: 1,029,642\n",
            "Trainable params: 1,029,642\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 23.34\n",
            "Params size (MB): 3.93\n",
            "Estimated Total Size (MB): 27.27\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "[1/1] Loss_D: 0.9536 Loss_G: 0.0835 D(x): 0.4738 D(G(z)): 0.4273 batch_size: 1065.0000: 100%|██████████| 17/17 [00:10<00:00,  2.09it/s]\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------\n",
            "LR image size:[41, 3, 22, 22]\n",
            "\n",
            "SR image size:[41, 3, 88, 88]\n",
            "\n",
            "-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:121: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:122: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "[converting LR images to SR images] PSNR: 17.0939 dB : 100%|██████████| 32/32 [00:02<00:00, 14.11it/s]\n",
            "[saving training results]: 100%|██████████| 6/6 [00:05<00:00,  1.17it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw-NlJLoJjMl",
        "colab_type": "text"
      },
      "source": [
        "# generator parameters: 669594\n",
        "# discriminator parameters: 5215425\n",
        "\n",
        "  0%|          | 0/17 [00:00<?, ?it/s]\n",
        "---------------------------------------------------------------------------\n",
        "TypeError                                 Traceback (most recent call last)\n",
        "<ipython-input-18-8a6e2b51ad98> in <module>()\n",
        "     69         if torch.cuda.is_available():\n",
        "     70             z = z.cuda()\n",
        "---> 71         fake_img = netG(z)\n",
        "     72 \n",
        "     73         netD.zero_grad()\n",
        "\n",
        "7 frames\n",
        "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/pixelshuffle.py in forward(self, input)\n",
        "     44     @weak_script_method\n",
        "     45     def forward(self, input):\n",
        "---> 46         return F.pixel_shuffle(input, self.upscale_factor)\n",
        "     47 \n",
        "     48     def extra_repr(self):\n",
        "\n",
        "TypeError: pixel_shuffle(): argument 'upscale_factor' (position 2) must be int, not float"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFE--EjSJkki",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_oETDBXWDRh",
        "colab_type": "text"
      },
      "source": [
        "single image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plSgn-wwVIRp",
        "colab_type": "code",
        "outputId": "67a2f945-727f-43ae-bdef-550703c40bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# import argparse\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "\n",
        "UPSCALE_FACTOR = 4 \n",
        "TEST_MODE = True #True if opt.test_mode == 'GPU' else False\n",
        "IMAGE_NAME = 'p3_4d.jpg'\n",
        "MODEL_NAME = 'netG_epoch_4_931.pth'  \n",
        "\n",
        "model = Generator(UPSCALE_FACTOR).eval()\n",
        "if TEST_MODE:\n",
        "    model.cuda()\n",
        "    model.load_state_dict(torch.load( MODEL_NAME)) \n",
        "else:\n",
        "    model.load_state_dict(torch.load( MODEL_NAME, map_location=lambda storage, loc: storage)) \n",
        "\n",
        "image = Image.open(IMAGE_NAME)\n",
        "image = Variable(ToTensor()(image), volatile=True).unsqueeze(0)\n",
        "if TEST_MODE:\n",
        "    image = image.cuda()\n",
        "\n",
        "start = time.clock()\n",
        "out = model(image)\n",
        "elapsed = (time.clock() - start)\n",
        "print('cost' + str(elapsed) + 's')\n",
        "out_img = ToPILImage()(out[0].data.cpu())\n",
        "out_img.save('out_srf_' + str(UPSCALE_FACTOR) + '_' + IMAGE_NAME)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cost0.003672999999999149s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi6_79EID4ki",
        "colab_type": "text"
      },
      "source": [
        "Single Image with PSNR calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YGqJ53bVIGt",
        "colab_type": "code",
        "outputId": "72d6231c-cb68-4691-e164-796c57a4bf5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "from math import log10\n",
        "\n",
        "\n",
        "UPSCALE_FACTOR = 4\n",
        "TEST_MODE = True #True if opt.test_mode == 'GPU' else False\n",
        "IMAGE_NAME = 'p3_4d.jpg'\n",
        "MODEL_NAME = 'netG_epoch_4_931.pth' \n",
        "hr_image = 'p3.jpg'\n",
        "\n",
        "model = Generator(UPSCALE_FACTOR).eval()\n",
        "if TEST_MODE:\n",
        "    model.cuda()\n",
        "    model.load_state_dict(torch.load( MODEL_NAME))\n",
        "else:\n",
        "    model.load_state_dict(torch.load( MODEL_NAME, map_location=lambda storage, loc: storage)) \n",
        "\n",
        "image = Image.open(IMAGE_NAME)\n",
        "hr = Image.open(hr_image)\n",
        "\n",
        "image = Variable(ToTensor()(image), volatile=True).unsqueeze(0)\n",
        "hr = Variable(ToTensor()(hr), volatile=True).unsqueeze(0)\n",
        "\n",
        "if TEST_MODE:\n",
        "    image = image.cuda()\n",
        "    hr = hr.cuda()\n",
        "\n",
        "start = time.clock()\n",
        "out = model(image)\n",
        "elapsed = (time.clock() - start)\n",
        "print('cost for {}:{}s\\n'.format(IMAGE_NAME,str(elapsed)))\n",
        "\n",
        "# print('cost' + str(elapsed) + 's')\n",
        "mse = ((hr - out) ** 2).data.mean()\n",
        "psnr = 10 * log10(1 / mse)\n",
        "print('PSNR value for {}:{}\\n'.format(IMAGE_NAME,psnr))\n",
        "out_img = ToPILImage()(out[0].data.cpu())\n",
        "out_img.save('out_srf_' + str(UPSCALE_FACTOR) + '_' + IMAGE_NAME)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cost for p3_4d.jpg:0.0040639999999996235s\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-4db78165928b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# print('cost' + str(elapsed) + 's')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mpsnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PSNR value for {}:{}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpsnr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (706) must match the size of tensor b (704) at non-singleton dimension 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRi54-WoEmS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.get_device_name(torch.cuda.current_device())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrDWqSUeYv15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hr_image = 'baby_rlt.png'\n",
        "# hr = Image.open(hr_image)\n",
        "# hr = Variable(ToTensor()(hr), volatile=True)\n",
        "\n",
        "# mse = ((hr - out_t) ** 2).data.mean()\n",
        "# psnr = 10 * log10(1 / mse)\n",
        "# print(psnr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIUmarjdbDAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# data = pd.read_csv('srf_5_train_results111.csv')\n",
        "# data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppznOkZM8SWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# epochs = data.iloc[:,0]\n",
        "# loss_d = data['Loss_D']\n",
        "# # loss_d.head()\n",
        "\n",
        "# loss_g = data['Loss_G']\n",
        "# # loss_g.head()\n",
        "# epochs.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdbY-mwa8y_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.plot(epochs, loss_g)\n",
        "# plt.ylabel('Generator Loss')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.savefig('Generator_loss_100epx5')\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itxhueoy9lFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.plot(epochs, loss_d)\n",
        "# plt.ylabel('Discriminator Loss')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.savefig('Discriminator_loss_100epx5')\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI-Hlkt8T10-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzyBa-pS-w5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}